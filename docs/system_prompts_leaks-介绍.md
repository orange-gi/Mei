# System Prompts Leaks 项目介绍

## 为什么 (Why)

### 项目背景与动机

System Prompts Leaks 项目源于AI社区对大型语言模型系统提示词的浓厚兴趣和研究需求。随着Claude、GPT-4、Gemini等AI助手在各个领域的广泛应用,这些AI系统的"系统提示词"——即定义AI行为模式、约束条件和使用规则的底层指令——逐渐成为研究者和开发者关注的焦点。

系统提示词是AI模型响应的基础框架,它们决定了AI如何处理用户请求、如何遵循安全准则、如何运用工具以及如何与外部服务交互。理解这些提示词不仅有助于深入了解AI系统的工作原理,还能为提示词工程提供宝贵的参考。

### 解决的核心问题

1. **信息不透明问题**: 主流AI服务商的系统提示词通常是闭源的,用户和开发者难以了解AI系统的完整行为规范
2. **研究资源匮乏**: 缺乏系统性的、系统级的AI提示词参考资料,限制了AI可解释性和安全性研究
3. **开发参考缺失**: 开发者需要了解优秀的提示词设计模式,但缺乏可参考的真实案例

### 目标用户群体

- **AI研究者**: 进行AI行为分析、可解释性和安全性研究
- **提示词工程师**: 学习和借鉴专业的提示词设计技巧
- **开发者**: 了解如何构建AI应用和集成AI能力
- **安全研究人员**: 分析AI系统的边界和限制条件
- **技术爱好者**: 对AI技术原理感兴趣的技术社区成员

## 是什么 (What)

### 项目概述

System Prompts Leaks 是一个开源项目,致力于收集、整理和分享来自各大AI服务商的系统提示词。该项目通过社区协作的方式,收集并验证各类AI助手的系统提示词,并以结构化的方式呈现给研究者和开发者。

### 核心功能

1. **提示词收集**: 从多种渠道收集AI系统的系统提示词
2. **分类整理**: 按AI服务商和版本进行分类存储
3. **版本追踪**: 记录不同时间段的提示词版本,便于版本对比分析
4. **社区协作**: 鼓励社区成员贡献和更新提示词内容

### 主要提供商和模型

项目涵盖了以下主要AI提供商的系统提示词:

- **Anthropic**: Claude系列(包括Claude 3.7、4.0、4.5等版本)
- **OpenAI**: GPT-4系列、GPT-5系列(包括不同配置和模式)
- **Google**: Gemini系列
- **xAI**: Grok系列
- **Perplexity**: AI搜索助手
- **Proton**: 隐私导向的AI服务

### 目录结构

```
system_prompts_leaks/
├── Anthropic/          # Anthropic Claude系列提示词
│   ├── claude-3.7-sonnet-w-tools.md
│   ├── claude-4.5-sonnet.md
│   ├── claude-code.md
│   └── ...
├── OpenAI/            # OpenAI GPT系列提示词
│   ├── GPT-4o.md
│   ├── gpt-5-thinking.md
│   ├── gpt-5-agent-mode.md
│   └── ...
├── Google/            # Google Gemini系列提示词
├── xAI/               # xAI Grok系列提示词
├── Perplexity/        # Perplexity AI提示词
├── Proton/            # Proton AI提示词
├── Misc/              # 其他AI服务的提示词
└── claude.txt         # 根目录的Claude提示词副本
```

### 技术特点

1. **多格式支持**: 提供Markdown、XML、TXT等多种格式
2. **版本追踪**: 记录提示词的时间戳和版本信息
3. **工具定义**: 包含完整的工具使用说明和约束条件
4. **跨版本对比**: 支持分析同一模型不同版本间的提示词变化

## 如何做 (How)

### 快速开始

#### 1. 浏览和查看提示词

```bash
# 克隆项目
git clone https://github.com/asgeirtj/system_prompts_leaks.git
cd system_prompts_leaks

# 查看目录结构
ls -la

# 进入特定提供商的目录
cd Anthropic
ls -la
```

#### 2. 使用提示词进行分析

查看特定模型的系统提示词:

```bash
# 查看Claude 4.5 Sonnet的完整提示词
cat Anthropic/claude-4.5-sonnet.md

# 查看GPT-4o的提示词
cat OpenAI/GPT-4o.md

# 查看GPT-5 Thinking模式的提示词
cat OpenAI/gpt-5-thinking.md
```

### 核心使用方式

#### 1. 学习提示词工程

通过分析收集的提示词,学习专业的提示词设计技巧:

- **指令结构**: 了解如何组织清晰、层次分明的指令
- **约束条件**: 学习如何设置有效的行为边界
- **工具使用**: 掌握如何定义和限制工具调用
- **输出格式**: 理解如何规范输出格式和响应风格

#### 2. 版本对比分析

比较同一模型不同版本间的提示词变化:

```bash
# 对比Claude 3.7和4.5的提示词差异
diff Anthropic/claude-3.7-sonnet-w-tools.md Anthropic/claude-4.5-sonnet.md

# 对比GPT-4o和GPT-5的提示词变化
diff OpenAI/GPT-4o.md OpenAI/gpt-5-thinking.md
```

#### 3. 研究AI行为模式

分析提示词中的关键组件:

- **系统定义**: AI的角色和能力边界
- **工具约束**: 可用工具及其使用限制
- **安全准则**: 内容过滤和行为规范
- **交互模式**: 响应风格和沟通方式

### 关键配置说明

#### 提示词结构分析

以Claude 4.5 Sonnet的提示词为例,典型的系统提示词包含以下部分:

1. **元信息**: 知识截止日期、当前日期、模型版本
2. **系统角色**: AI的身份定义和能力范围
3. **工具定义**: 可用工具及其参数说明
4. **行为准则**: 响应规则和约束条件
5. **安全策略**: 内容过滤和伦理边界
6. **交互风格**: 沟通方式和格式化要求

#### 提示词设计最佳实践

1. **明确性**: 使用清晰、具体的指令语言
2. **层次性**: 按重要性组织指令结构
3. **完整性**: 覆盖所有必要的场景和边界条件
4. **一致性**: 保持风格和格式的统一
5. **可维护性**: 结构化的设计便于更新和扩展

### 进阶使用

#### 1. 贡献新内容

向项目贡献新的提示词:

1. Fork项目仓库
2. 创建新的分支
3. 在相应目录下添加提示词文件
4. 遵循项目的命名规范和格式要求
5. 提交Pull Request

#### 2. 数据分析

利用收集的提示词进行数据分析:

```python
# 示例:分析提示词长度分布
import os
import glob

prompt_files = glob.glob("**/*.md", recursive=True)
lengths = []

for file in prompt_files:
    with open(file, 'r', encoding='utf-8') as f:
        content = f.read()
        lengths.append(len(content))

print(f"平均提示词长度: {sum(lengths)/len(lengths):.0f} 字符")
print(f"最长提示词: {max(lengths)} 字符")
print(f"最短提示词: {min(lengths)} 字符")
```

#### 3. 版本追踪

定期检查提示词的变化:

```bash
# 使用git进行版本追踪
git log --oneline --all -- "Anthropic/*.md" | head -20

# 查看特定文件的历史
git log -p Anthropic/claude-4.5-sonnet.md | head -100
```

### 最佳实践建议

1. **定期更新**: 由于AI服务商会更新提示词,建议定期拉取最新版本
2. **版本对照**: 使用版本控制系统跟踪提示词的历史变化
3. **交叉验证**: 通过多个渠道验证提示词的准确性和完整性
4. **尊重限制**: 了解并遵守AI服务商的使用条款和政策
5. **研究伦理**: 将提示词用于学术研究和教育目的

## 未来展望

### 项目发展方向

1. **扩展覆盖范围**: 纳入更多AI服务商的系统提示词
2. **增强结构化**: 提供更丰富的元数据和结构化信息
3. **分析工具**: 开发专门的分析和可视化工具
4. **社区建设**: 扩大社区参与和贡献者网络

### 研究价值

System Prompts Leaks项目为以下领域提供了宝贵的研究资源:

- **AI可解释性研究**: 理解AI决策过程和推理机制
- **安全性分析**: 评估和改进AI系统的安全边界
- **提示词工程**: 发展和优化提示词设计方法论
- **AI伦理研究**: 分析和探讨AI行为准则的合理性
