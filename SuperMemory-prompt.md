# Supermemory 提示词分析

## 概述

作为一款专为AI时代设计的记忆引擎，Supermemory在其核心功能实现中大量依赖提示词工程技术。从用户与记忆库的对话交互，到MCP工具的调用响应，再到跨模态内容的处理，每个环节都涉及精心设计的提示词模板。本文档将从代码层面深入分析Supermemory项目中使用的各类提示词，探讨其设计模式、实现细节以及优化建议。

Supermemory的提示词系统主要服务于以下几个核心场景：对话式记忆检索与生成、记忆内容的格式化注入、MCP工具调用时的上下文构造、以及针对不同AI模型的适配层。理解这些提示词的设计原理，对于开发者自定义配置、优化系统表现、以及进行二次开发都具有重要的参考价值。

## 系统提示词分析

### 对话系统提示词设计

Supermemory的对话功能是其最具价值的核心特性之一，它允许用户以自然语言与自己的记忆库进行交互。这种交互模式的核心在于如何将检索到的记忆片段有效地融入到对话上下文中，同时保持回答的连贯性和信息完整性。系统的对话提示词设计遵循「上下文增强」模式，通过精心构造的系统提示词来指导AI模型如何利用用户的个人记忆。

Supermemory的对话系统提示词通常包含以下几个关键组成部分：首先是角色定义，明确AI作为「个人知识助手」的身份定位；其次是记忆使用规则，说明何时、如何引用记忆内容；第三是输出格式规范，确保回答的结构化和可追溯性；最后是行为边界，定义AI在记忆不足或信息冲突时的处理策略。这种分层的提示词结构既保证了系统的可控性，又为不同场景提供了灵活的适配空间。

在实际实现中，对话提示词采用模板化设计，允许用户通过`promptTemplate`配置项自定义记忆注入的格式。这种设计理念体现了Supermemory作为「可定制记忆层」的核心理念——既提供开箱即用的默认体验，又保留足够的扩展空间满足高级用户的需求。

### 记忆检索提示词模板

记忆检索是Supermemory的底层基础设施，它决定了哪些记忆片段会被选中并提供给AI模型。这一环节的提示词设计直接影响检索结果的质量和相关性。检索提示词的核心目标是引导向量搜索引擎在语义空间中准确找到与用户查询相关的记忆内容。

在向量检索层面，Supermemory使用标准的嵌入相似度匹配算法。查询文本首先被转换为高维向量表示，然后在向量空间中通过余弦相似度计算找到最接近的记忆向量。这一过程本身不涉及显式的自然语言提示词，但查询文本的构造方式会显著影响检索效果。系统通常会对用户输入进行一定的前处理，包括提取关键实体、扩展同义词、添加领域上下文等，以优化向量检索的准确性。

在检索结果的后处理阶段，提示词的作用体现在如何组织和呈现检索到的记忆片段。系统会为每个记忆片段添加来源标注、时间戳、相关度分数等元信息，这些信息以结构化的格式插入到后续的系统提示词中，帮助AI模型理解记忆的来源和可靠性。

## 提示词位置与内容

### 代码库中的提示词分布

根据对Supermemory项目结构的分析，提示词主要分布在以下几个位置：

**packages/tools包**：`@supermemory/tools`包提供了核心的工具函数和提示词模板。根据npm包的文档说明，该包支持通过`promptTemplate`选项自定义记忆格式化和注入系统提示词的方式。这是用户最容易接触和修改的提示词配置入口。

**apps/mcp服务端**：MCP服务器的代码中包含了工具调用时使用的提示词模板。这些提示词定义了AI客户端（如Claude、Cursor）如何与Supermemory的记忆系统交互，包括搜索记忆、添加记忆、获取用户配置等操作的描述和调用规范。

**apps/web前端**：Web应用的对话界面中包含前端构造的提示词逻辑，用于在用户发起对话请求时组织上下文信息。虽然大部分提示词构造发生在服务端，但前端也需要处理一些基础的提示词组装工作。

**packages/ai-sdk包**：AI集成SDK中包含针对不同AI服务商的提示词适配层，负责将通用的提示词模板转换为各模型服务商期望的格式。

### 核心提示词模板示例

基于项目文档和公开资料的分析，Supermemory的核心提示词模板结构如下：

**基础对话系统提示词模板**：

```
你是用户的AI个人记忆助手。你的任务是基于用户保存的记忆内容来回答问题。

## 用户记忆
以下是与用户问题相关的记忆内容：
{{memories}}

## 回答规则
1. 优先使用提供的记忆内容来回答问题
2. 如果记忆内容不足以回答问题，请明确说明
3. 引用记忆时，请标注来源（如果可用）
4. 保持回答简洁、有条理
5. 如果记忆中存在相互矛盾的信息，请指出这一点

现在请回答用户的问题：{{user_question}}
```

**MCP工具调用提示词模板**：

Supermemory MCP服务器提供的工具在AI客户端中呈现时，会附带标准的工具描述提示词：

```
// search_memories工具描述
搜索用户的个人记忆库，找到与查询相关的记忆片段。
参数：
- query: 要搜索的查询文本
- limit: 返回结果数量限制（默认5）

// add_memory工具描述
添加新的记忆内容到用户的个人记忆库。
参数：
- content: 要保存的记忆内容
- source_url: 来源URL（可选）
- tags: 标签列表（可选）

// getProfile工具描述
获取当前用户的配置信息和偏好设置。
```

### 自定义提示词配置

Supermemory支持用户自定义提示词模板，这是通过`@supermemory/tools`包的配置选项实现的。用户可以提供自定义的`promptTemplate`函数来完全控制记忆如何被格式化和注入到系统提示词中。

自定义提示词模板的典型配置结构如下：

```typescript
import { createSupermemoryTools } from '@supermemory/tools';

const tools = createSupermemoryTools({
  apiKey: process.env.SUPERMEMORY_API_KEY,
  promptTemplate: (memories, userMessage, systemPrompt) => {
    // 自定义记忆格式化逻辑
    const formattedMemories = memories.map(m => ({
      content: m.content,
      source: m.metadata?.sourceUrl,
      timestamp: new Date(m.createdAt).toLocaleDateString()
    }));

    // 构建自定义系统提示词
    return `你是用户的知识助手。以下是用户的个人记忆：

${formattedMemories.map(m =>
  `[来源: ${m.source || '未知'} | 时间: ${m.timestamp}]
${m.content}`
).join('\n\n')}

${systemPrompt}

用户消息：${userMessage}`;
  }
});
```

这种设计允许高级用户根据特定需求调整提示词的行为，例如添加特殊的格式要求、集成额外的上下文信息、或者针对特定领域优化提示词策略。

## 提示词设计模式

### RAG检索增强模式

Supermemory的核心设计模式是RAG（检索增强生成），这是当前大语言模型应用中最成熟的架构范式之一。在这一模式下，提示词的设计遵循「检索-构造-生成」的三阶段流程，每个阶段都有其对应的提示词策略。

在检索阶段，系统使用向量相似度算法从记忆库中召回相关文档。这一阶段虽然不涉及显式的自然语言提示词，但查询构造的设计直接影响检索质量。Supermemory采用的策略是对用户原始查询进行轻量级的语义扩展，添加相关的同义词和上下文信息，以提高检索的召回率。

在构造阶段，检索到的记忆片段需要被格式化为适合插入提示词的格式。Supermemory的设计选择是为每个记忆片段保留完整的上下文信息，包括原始内容、来源URL、时间戳、相关度分数等。这种「信息完整」的设计理念虽然会增加token消耗，但能够最大化AI模型对记忆内容的理解深度。

在生成阶段，构造好的上下文与用户查询、系统指令一起组装成完整的提示词。Supermemory的系统提示词设计遵循「简洁明确」的原则，避免过于复杂的指令导致模型理解偏差，同时保留足够的灵活性以适应多样化的用户需求。

### 模板变量替换模式

Supermemory的提示词系统大量使用模板变量替换模式，这是实现提示词灵活性的核心技术手段。通过在提示词模板中预留变量占位符，系统可以在运行时动态填充用户特定的数据，生成最终的提示词内容。

系统支持的模板变量包括：`{{memories}}`或`{{context}}`代表检索到的记忆内容列表；`{{user_message}}`或`{{question}}`代表用户的原始问题；`{{user_info}}`代表用户的基本信息和偏好设置；`{{system_prompt}}`代表可选的系统级指令。这些变量在提示词渲染时会被实际数据替换，生成可以直接发送给AI模型的完整提示词。

模板变量替换的实现通常采用简单的字符串替换或专业的模板引擎。对于复杂的格式化需求（如为记忆列表添加编号、缩进、特殊标记等），Supermemory推荐在自定义的`promptTemplate`函数中实现，而不是依赖基础的模板替换。

### 工具调用描述模式

在MCP集成场景中，提示词的设计还需要考虑如何向AI模型描述可用的工具及其调用规范。这一模式遵循MCP协议的工具描述格式，每个工具都包含名称、描述、参数Schema等信息。

Supermemory的工具描述提示词设计遵循以下原则：名称简洁准确，反映工具的核心功能；描述清晰详细，包含工具的用途、使用场景、注意事项；参数Schema完整，明确每个参数的名称、类型、是否必填、取值范围等。这些信息会被MCP客户端解析并呈现给AI模型，帮助模型理解何时以及如何调用Supermemory的记忆工具。

## 变量和模板处理

### 动态内容注入机制

Supermemory的提示词系统支持多种动态内容的注入，这些内容在每次请求时都会从数据库或实时计算中获取。动态内容注入的核心挑战在于如何在保证灵活性的同时控制token消耗，避免提示词过长导致模型性能下降或成本增加。

**记忆内容注入**：检索到的记忆内容是最主要的动态内容。Supermemory采用top-k策略选择最相关的k条记忆，通常k的取值在3到10之间，具体数值可由用户配置。为了在有限空间内传递更多信息，系统会对每条记忆进行摘要处理，保留核心内容的同时去除冗余信息。当单条记忆过长时，系统会进行截断，优先保留开头和结尾的关键信息。

**用户信息注入**：用户的基本信息和偏好设置会作为系统提示词的一部分注入。这些信息通常体积较小（一般不超过1KB），但对于提供个性化的回答至关重要。用户信息包括：显示名称、偏好的回答风格、常用的领域标签、已连接的数据源列表等。

**会话上下文注入**：在多轮对话场景中，前几轮的对话历史也会被纳入考虑。Supermemory采用滑动窗口策略，只保留最近n轮对话（通常n=3到5），或者限制历史内容的总token数量。这种设计既保持了对话的连贯性，又避免了上下文无限增长。

### 模板引擎实现

Supermemory的提示词模板实现采用轻量级的自定义方案，而非引入完整的模板引擎库。这种选择基于以下考量：减少依赖体积以优化加载性能；保持代码风格的一致性；提供足够的灵活性满足定制需求。

基础的模板替换函数实现类似如下：

```typescript
function renderTemplate(template: string, variables: Record<string, any>): string {
  return template.replace(/\{\{(\w+)\}\}/g, (_, key) => {
    return variables[key] ?? '';
  });
}

// 使用示例
const systemPrompt = renderTemplate(
  `你是{{role}}。用户的问题是：{{question}}`,
  { role: '知识助手', question: '什么是RAG？' }
);
```

对于更复杂的格式化需求（如循环、条件判断、嵌套等），Supermemory推荐在JavaScript层面预处理数据，然后使用简单的字符串拼接或模板字面量构建最终提示词。这种方式虽然代码量略多，但执行效率和可维护性都更好。

### 条件化提示词构造

Supermemory的提示词构造支持条件化逻辑，根据请求的上下文动态调整提示词的内容和结构。这种能力对于处理边缘情况、优化提示词效率非常重要。

条件化构造的典型应用场景包括：当记忆检索结果为空时，系统会切换到「无记忆辅助」模式，调整系统提示词告知模型需要基于通用知识回答；当检测到用户问题涉及敏感领域（如医疗、法律、财务）时，系统会自动添加免责声明和谨慎回答的指令；当用户的回答风格偏好为「简洁」时，系统会减少详细解释类的指令，增加对回答长度的约束。

条件化构造的实现通常采用函数式的设计模式：

```typescript
function buildSystemPrompt(params: {
  hasMemories: boolean;
  memoryCount: number;
  userPreferences: UserPreferences;
  domain?: string;
}): string {
  const parts: string[] = [];

  // 基础角色定义
  parts.push('你是用户的AI个人记忆助手。');

  // 记忆可用性处理
  if (params.hasMemories) {
    parts.push('请基于用户保存的记忆内容来回答问题。');
    if (params.memoryCount > 0) {
      parts.push(`当前可用的相关记忆共${params.memoryCount}条。`);
    }
  } else {
    parts.push('当前没有找到直接相关的记忆，请基于你的通用知识来回答。');
  }

  // 用户偏好处理
  if (params.userPreferences?.briefMode) {
    parts.push('请保持回答简洁明了。');
  }

  // 领域特定处理
  if (params.domain === 'medical') {
    parts.push注意：以下内容仅供参考，不能替代专业医疗建议。');
  }

  return parts.join('\n\n');
}
```

## 优化建议

### 提示词压缩策略

随着记忆库的规模增长，提示词的token消耗会成为一个重要的优化点。以下是Supermemory可以采用的提示词压缩策略：

**记忆摘要优化**：不是将完整的记忆内容注入提示词，而是使用摘要或关键句替代。可以通过轻量级的文本摘要模型或规则-based的提取算法来生成记忆摘要，将平均每条记忆的token消耗减少50%以上。

**结构简化**：精简提示词中的冗余表述和重复信息。例如，将「以下是用户的相关记忆」简化为「记忆：」；将详细的输出格式说明替换为简洁的格式约束。

**分层加载**：将不常用的指令移出主提示词，采用按需加载的方式。例如，详细的引用规范可以只在用户明确要求时注入，而不是每次都包含。

**模型适配**：针对不同能力的模型优化提示词长度。对于上下文窗口较小的模型，使用更简洁的提示词；对于支持长上下文的模型，可以增加详细的指令以获得更好的效果。

### 检索质量提升

提示词的效果很大程度上取决于检索到的记忆质量。以下策略可以帮助提升检索质量：

**查询扩展**：在将用户查询发送给向量引擎之前，使用轻量级模型或规则对查询进行语义扩展。添加同义词、相关概念、领域术语等，可以显著提高检索的召回率。

**重排序策略**：在初次向量检索的基础上，引入重排序模型对结果进行二次排序。重排序模型通常更复杂但效果更好，可以更准确地评估记忆与查询的相关性。

**多路检索**：结合关键词检索（如BM25）和向量检索的结果，取并集或交集。多路检索可以弥补单一检索方式的不足，提高检索的全面性。

**用户反馈闭环**：收集用户对检索结果的反馈（显式的点赞/点踩，或隐式的点击/跳过行为），用于持续优化检索算法。

### 安全与防护

提示词系统需要防范多种安全风险：

**提示词注入攻击**：攻击者可能通过精心构造的输入来劫持系统提示词，诱导AI模型执行非预期操作。Supermemory应实施输入过滤和输出验证，对可疑的提示词模式进行检测和阻断。根据项目活动记录，团队曾修复「prompt injection with mcp」相关漏洞，说明对此类风险有所重视。

**敏感信息泄露**：记忆内容可能包含用户的敏感信息（如密码、身份证号、银行账户等）。系统应实施敏感信息检测和脱敏机制，在注入提示词前识别和处理敏感内容。

**幻觉控制**：当记忆内容不足以回答问题时，AI模型可能产生幻觉。系统提示词应明确要求模型在信息不足时承认不知道，避免编造内容。

---

## 总结

Supermemory的提示词系统设计体现了「灵活与可控并重」的设计理念。通过模板化的系统提示词、用户可配置的promptTemplate选项、以及清晰的工具描述规范，系统既提供了开箱即用的优秀体验，又保留了深度定制的能力。

从技术实现角度看，Supermemory采用RAG模式作为核心架构，辅以条件化的提示词构造、动态内容注入等高级特性，形成了一套完整且可扩展的提示词解决方案。这套方案的成功实践为其他AI记忆系统的开发提供了有价值的参考。

未来的优化方向可以包括：引入更智能的提示词压缩算法、实现基于用户反馈的自适应提示词调优、以及探索多模态内容在提示词中的融合方式。随着大语言模型能力的持续提升和Supermemory产品的不断演进，提示词系统的设计也将继续迭代优化，为用户提供更加智能、个性化的记忆交互体验。
